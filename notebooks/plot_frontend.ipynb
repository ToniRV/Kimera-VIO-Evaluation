{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Frontend\n",
    "\n",
    "Plots statistics and data collected from the frontend related to feature detection,\n",
    "RANSAC pose recovery, sparse stereo matching and timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "if not log.handlers:\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    ch.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n",
    "    log.addHandler(ch)\n",
    "    \n",
    "from evo.tools import file_interface\n",
    "from evo.tools import plot\n",
    "from evo.tools import pandas_bridge\n",
    "\n",
    "from evo.core import sync\n",
    "from evo.core import trajectory\n",
    "from evo.core import metrics\n",
    "from evo.core import transformations\n",
    "from evo.core import lie_algebra as lie\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import evaluation.tools as evt\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Locations\n",
    "\n",
    "Make sure to set the following paths.\n",
    "\n",
    "`vio_output_dir` is the path to the directory containing `output_*.csv` files obtained from logging a run of SparkVio.\n",
    "\n",
    "`gt_data_file` is the absolute path to the `csv` file containing ground truth data for the absolute pose at each timestamp of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory to VIO output csv files as well as ground truth absolute poses.\n",
    "# vio_ooutput_logs\n",
    "vio_output_dir = \"/home/marcus/catkin_ws/src/Kimera-VIO/output_logs/\"\n",
    "gt_data_file = \"/home/marcus/catkin_ws/src/Kimera-VIO/output_logs/traj_gt.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontend Statistics\n",
    "\n",
    "Calculate and plot important statistics from the frontend of the VIO module\n",
    "\n",
    "These statistics include the number of tracked and detected features, data relating the RANSAC runs for both mono 5-point and stereo 3-point methods, timing data and sparse-stereo-matching statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse frontend statistics csv file.\n",
    "stats_file = os.path.join(os.path.expandvars(vio_output_dir), \"output_frontend_stats.csv\")\n",
    "\n",
    "# Convert to tidy pandas DataFrame object.\n",
    "df_stats = pd.read_csv(stats_file, sep=',', index_col=False)\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for processing data summary.\n",
    "def get_mean(attrib):\n",
    "    ls = df_stats[attrib].tolist()\n",
    "    return float(sum(ls)) / len(ls)\n",
    "\n",
    "def get_min(attrib):\n",
    "    return min(df_stats[attrib])\n",
    "\n",
    "def get_max(attrib):\n",
    "    return max(df_stats[attrib])\n",
    "\n",
    "# Construct and visualize summary. TODO(marcus): use a LaTeX table.\n",
    "summary_stats = [\n",
    "    (\"Average number of detected features\", get_mean(\"nrDetectedFeatures\")),\n",
    "    (\"Minimum number of detected features\", get_min(\"nrDetectedFeatures\")),\n",
    "    (\"Average number of tracked features\" , get_mean(\"nrTrackerFeatures\")),\n",
    "    (\"Minimum number of tracked features\", get_min(\"nrTrackerFeatures\")),\n",
    "    (\"Average number of mono ransac inliers\", get_mean(\"nrMonoInliers\")),\n",
    "    (\"Minimum number of mono ransac inliers\", get_min(\"nrMonoInliers\")),\n",
    "    (\"Average number of stereo ransac inliers\", get_mean(\"nrStereoInliers\")),\n",
    "    (\"Minimum number of stereo ransac inliers\", get_min(\"nrStereoInliers\")),\n",
    "    (\"Average number of mono ransac putatives\", get_mean(\"nrMonoPutatives\")),\n",
    "    (\"Minimum number of mono ransac putatives\", get_min(\"nrMonoPutatives\")),\n",
    "    (\"Average number of stereo ransac putatives\", get_mean(\"nrStereoPutatives\")),\n",
    "    (\"Minimum number of stereo ransac putatives\", get_min(\"nrStereoPutatives\")),\n",
    "]\n",
    "\n",
    "attrib_len = [len(attrib[0]) for attrib in summary_stats]\n",
    "max_attrib_len = max(attrib_len)\n",
    "\n",
    "print(\"\\nStatistic summary:\\n\")\n",
    "for entry in summary_stats:\n",
    "    attrib = entry[0]\n",
    "    value = entry[1]\n",
    "    spacing = max_attrib_len - len(attrib)\n",
    "    print(attrib + \" \"*spacing + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot feature tracking statistics.\n",
    "use_plotly = False\n",
    "\n",
    "if not use_plotly:\n",
    "    fig0, axes0 = plt.subplots(nrows=1, ncols=1, figsize=(18,10), squeeze=False)\n",
    "    df_stats.plot(kind=\"line\", y=\"nrDetectedFeatures\", ax=axes0[0,0])\n",
    "    df_stats.plot(kind=\"line\", y=\"nrTrackerFeatures\", ax=axes0[0,0])\n",
    "    plt.show()\n",
    "else:\n",
    "    evt.draw_feature_tracking_stats(df_stats, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot ransac inlier, putative and iteration statistics.\n",
    "if not use_plotly:\n",
    "    fig1, axes1 = plt.subplots(nrows=1, ncols=3, figsize=(18,10), squeeze=False)\n",
    "    df_stats.plot(kind=\"line\", y=\"nrMonoInliers\", ax=axes1[0,0])\n",
    "    df_stats.plot(kind=\"line\", y=\"nrMonoPutatives\", ax=axes1[0,0])\n",
    "    df_stats.plot(kind=\"line\", y=\"nrStereoInliers\", ax=axes1[0,1])\n",
    "    df_stats.plot(kind=\"line\", y=\"nrStereoPutatives\", ax=axes1[0,1])\n",
    "    df_stats.plot(kind=\"line\", y=\"monoRansacIters\", ax=axes1[0,2])\n",
    "    df_stats.plot(kind=\"line\", y=\"stereoRansacIters\", ax=axes1[0,2])\n",
    "    plt.show()\n",
    "else:\n",
    "    evt.draw_mono_stereo_inliers_outliers(df_stats, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot sparse-stereo-matching statistics.\n",
    "\n",
    "fig3, axes3 = plt.subplots(nrows=1, ncols=4, figsize=(18,10), squeeze=False)\n",
    "\n",
    "df_stats.plot(kind=\"line\", y=\"nrValidRKP\", ax=axes3[0,0])\n",
    "df_stats.plot(kind=\"line\", y=\"nrNoLeftRectRKP\", ax=axes3[0,1])\n",
    "df_stats.plot(kind=\"line\", y=\"nrNoRightRectRKP\", ax=axes3[0,1])\n",
    "df_stats.plot(kind=\"line\", y=\"nrNoDepthRKP\", ax=axes3[0,2])\n",
    "df_stats.plot(kind=\"line\", y=\"nrFailedArunRKP\", ax=axes3[0,3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot timing statistics.\n",
    "if not use_plotly:\n",
    "    fig2, axes2 = plt.subplots(nrows=1, ncols=5, figsize=(18,10), squeeze=False)\n",
    "    df_stats.plot(kind=\"line\", y=\"featureDetectionTime\", ax=axes2[0,0])\n",
    "    df_stats.plot(kind=\"line\", y=\"featureTrackingTime\", ax=axes2[0,1])\n",
    "    df_stats.plot(kind=\"line\", y=\"monoRansacTime\", ax=axes2[0,2])\n",
    "    df_stats.plot(kind=\"line\", y=\"stereoRansacTime\", ax=axes2[0,3])\n",
    "    df_stats.plot(kind=\"line\", y=\"featureSelectionTime\", ax=axes2[0,4])\n",
    "    plt.show()\n",
    "else:\n",
    "    evt.draw_frontend_timing(df_stats, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Methods for RANSAC Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful methods for RPE calculation.\n",
    "\n",
    "def get_rpe(data, metric):\n",
    "    \"\"\" Gets RPE and RPE statistics for two trajectories and a given pose_relation.\n",
    "        \n",
    "        Args:\n",
    "            data:   tuple of trajectories, the first being the reference trajectory\n",
    "                    and the second being the estimated trajectory.\n",
    "            metric: a metrics.PoseRelation instance representing the pose relation\n",
    "                    to use when computing RPE.\n",
    "        \n",
    "        Returns:\n",
    "            A metrics.RPE instance containing the RPE for both trajectories according\n",
    "            to the given metric.\n",
    "    \"\"\"\n",
    "    # normal mode\n",
    "    delta = 1\n",
    "    delta_unit = metrics.Unit.frames\n",
    "    all_pairs = False\n",
    "\n",
    "    rpe = metrics.RPE(metric, delta, delta_unit, all_pairs)\n",
    "    rpe.process_data(data)\n",
    "    return rpe\n",
    "\n",
    "\n",
    "def plot_rpe(x_axis, rpe, size=(18,10)):\n",
    "    \"\"\" Plots RPE error against time for a given metrics.RPE instance.\n",
    "    \n",
    "        Args:\n",
    "            x_axis: An array-type of values for all the x-axis values (time).\n",
    "            rpe:    A metrics.RPE instance with pre-processed data.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=size)\n",
    "    plot.error_array(fig, rpe.error, x_array=x_axis, statistics=rpe.get_all_statistics(), \n",
    "                     name=\"RPE\", title=\"RPE w.r.t. \" + rpe.pose_relation.value, xlabel=\"$t$ (s)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rename_euroc_gt_df(df):\n",
    "    \"\"\" Renames a DataFrame built from a EuRoC ground-truth data csv file to be easier to read.\n",
    "        \n",
    "        Column labels are changed to be more readable and to be identical to the generic pose \n",
    "        trajectory format used with other csv files. Note that '#timestamp' will not actually \n",
    "        be renamed if it is the index of the DataFrame (which it should be). It will be \n",
    "        appropriately renamed if it is the index name.\n",
    "        This operation is 'inplace': It does not return a new DataFrame but simply changes\n",
    "        the existing one.\n",
    "        \n",
    "        Args:\n",
    "            df: A pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "    df.index.names = [\"timestamp\"]\n",
    "    df.rename(columns={\" p_RS_R_x [m]\": \"x\",\n",
    "                       \" p_RS_R_y [m]\": \"y\",\n",
    "                       \" p_RS_R_z [m]\": \"z\",\n",
    "                       \" q_RS_w []\": \"qw\",\n",
    "                       \" q_RS_x []\": \"qx\",\n",
    "                       \" q_RS_y []\": \"qy\",\n",
    "                       \" q_RS_z []\": \"qz\",\n",
    "                       \" v_RS_R_x [m s^-1]\": \"vx\",\n",
    "                       \" v_RS_R_y [m s^-1]\": \"vy\",\n",
    "                       \" v_RS_R_z [m s^-1]\": \"vz\",\n",
    "                       \" b_w_RS_S_x [rad s^-1]\": \"bgx\",\n",
    "                       \" b_w_RS_S_y [rad s^-1]\": \"bgy\",\n",
    "                       \" b_w_RS_S_z [rad s^-1]\": \"bgz\",\n",
    "                       \" b_a_RS_S_x [m s^-2]\": \"bax\",\n",
    "                       \" b_a_RS_S_y [m s^-2]\": \"bay\",\n",
    "                       \" b_a_RS_S_z [m s^-2]\": \"baz\"}, inplace=True)\n",
    "\n",
    "\n",
    "def time_associate_df(ref_df, est_df):\n",
    "    \"\"\" Returns a copy of the reference DataFrame sliced row-wise so as to only contain rows\n",
    "        used in the estimated DataFrame.\n",
    "        \n",
    "        The argument 'ref_df' is the reference DataFrame and is sliced to only contain rows\n",
    "        that are in 'est_df' as well. Rows with 'NaN' values are dropped from the resulting\n",
    "        DataFrame before returning.\n",
    "        \n",
    "        Args:\n",
    "            ref_df: A pandas.DataFrame object representing the reference trajectory.\n",
    "            est_df: A pandas.DataFrame object representing the estimated trajectory.\n",
    "        \n",
    "        Returns:\n",
    "            res: A pandas.DataFrame object containing only the rows of 'ref_df' whos\n",
    "            indices are present in 'est_df'.\n",
    "    \"\"\"\n",
    "    res = ref_df.reindex(index=est_df.index)\n",
    "    res.dropna(inplace=True)\n",
    "    return res\n",
    "\n",
    "\n",
    "# TODO(marcus): implement the inverse operation to this one:\n",
    "# TODO(marcus): move to a library somewhere and write a unit test.\n",
    "def convert_abs_traj_to_rel_traj(df, to_scale=True):\n",
    "    \"\"\" Converts an absolute-pose trajectory to a relative-pose trajectory.\n",
    "    \n",
    "        The incoming DataFrame is processed element-wise. At each timestamp (which is the \n",
    "        index of the DataFrame row) starting from the second (index 1), the relative pose \n",
    "        from the previous timestamp to the current one is calculated (in the previous-\n",
    "        timestamp's coordinate frame). This relative pose is then appended to the \n",
    "        resulting DataFrame.\n",
    "        The resulting DataFrame has timestamp indices corresponding to poses that represent\n",
    "        the relative transformation between that timestamp and the **next** one.\n",
    "        \n",
    "        Args:\n",
    "            df: A pandas.DataFrame object with timestamps as indices containing, at a minimum,\n",
    "                columns representing the xyz position and wxyz quaternion-rotation at each\n",
    "                timestamp, corresponding to the absolute pose at that time.\n",
    "            to_scale: A boolean. If set to False, relative poses will have their translation\n",
    "                part normalized.\n",
    "        \n",
    "        Returns:\n",
    "            A pandas.DataFrame object with xyz position and wxyz quaternion fields for the \n",
    "            relative pose trajectory corresponding to the absolute one given in 'df'.\n",
    "    \"\"\"\n",
    "    rows_list = []\n",
    "    \n",
    "    prev_ts = df.index[0]\n",
    "    for i in range(len(df.index[1:])):\n",
    "        ts = df.index[i]\n",
    "        \n",
    "        w_t_bi = np.array([df.at[prev_ts, idx] for idx in ['x', 'y', 'z']])\n",
    "        w_q_bi = np.array([df.at[prev_ts, idx] for idx in ['qw', 'qx', 'qy', 'qz']])\n",
    "        w_T_bi = transformations.quaternion_matrix(w_q_bi)\n",
    "        w_T_bi[:3,3] = w_t_bi\n",
    "        \n",
    "        w_t_bidelta = np.array([df.at[ts, idx] for idx in ['x', 'y', 'z']])\n",
    "        w_q_bidelta = np.array([df.at[ts, idx] for idx in ['qw', 'qx', 'qy', 'qz']])    \n",
    "        w_T_bidelta = transformations.quaternion_matrix(w_q_bidelta)\n",
    "        w_T_bidelta[:3,3] = w_t_bidelta\n",
    "        \n",
    "        bi_T_bidelta = lie.relative_se3(w_T_bi, w_T_bidelta)\n",
    "        \n",
    "        bi_R_bidelta = copy.deepcopy(bi_T_bidelta)\n",
    "        bi_R_bidelta[:,3] = np.array([0, 0, 0, 1])\n",
    "        bi_q_bidelta = transformations.quaternion_from_matrix(bi_R_bidelta)\n",
    "        bi_t_bidelta = bi_T_bidelta[:3,3]\n",
    "        \n",
    "        if not to_scale:\n",
    "            norm = np.linalg.norm(bi_t_bidelta)\n",
    "            if norm > 1e-6:\n",
    "                bi_t_bidelta = bi_t_bidelta / np.linalg.norm(bi_t_bidelta)\n",
    "        \n",
    "        new_row = {'x': bi_t_bidelta[0], 'y': bi_t_bidelta[1], 'z': bi_t_bidelta[2],\n",
    "                   'qw': bi_q_bidelta[0], 'qx': bi_q_bidelta[1], 'qy': bi_q_bidelta[2],\n",
    "                   'qz': bi_q_bidelta[3],}\n",
    "        rows_list.append(new_row)\n",
    "        prev_ts = ts\n",
    "        \n",
    "    return pd.DataFrame(data=rows_list, index=df.index[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend Mono Ransac Poses (RPE)\n",
    "\n",
    "Calculate relative-pose-error (RPE) for the mono ransac poses obtained in the frontend.\n",
    "\n",
    "These are relative poses between keyframes and do not represent an entire trajectory. As such, they cannot be processed using the normal EVO evaluation pipeline.\n",
    "\n",
    "We import the csv data as Pandas DataFrame objects and perform our own data association. Relative poses for ground truth data are computed explicitly here. Rotation error and translation error (up to a scaling factor) are then calculated for each pair of consecutive keyframes.\n",
    "\n",
    "This gives insight into the accuracy of the RANSAC 5-point method employed in the frontend.\n",
    "\n",
    "\n",
    "NOTE: gt_df is read from the ground-truth csv. It expects the timestamp to be the first column. Make sure to comment out `rename_euroc_gt_df(gt_df)` in the second cell below if you are not using a csv with the EuRoC header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load ground truth and estimated data as csv DataFrames.\n",
    "gt_df = pd.read_csv(gt_data_file, sep=',', index_col=0)\n",
    "\n",
    "ransac_mono_filename = os.path.join(os.path.expandvars(vio_output_dir), \"output_frontend_ransac_mono.csv\")\n",
    "mono_df = pd.read_csv(ransac_mono_filename, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = gt_df[~gt_df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First make gt_df prettier.\n",
    "rename_euroc_gt_df(gt_df)\n",
    "\n",
    "gt_rel_df = convert_abs_traj_to_rel_traj(gt_df, to_scale=False)\n",
    "\n",
    "# convert to evo trajecotry objects\n",
    "traj_ref_unassociated = pandas_bridge.df_to_trajectory(gt_rel_df)\n",
    "\n",
    "# Use the mono ransac file as estimated trajectory.\n",
    "traj_est_unassociated = pandas_bridge.df_to_trajectory(mono_df)\n",
    "\n",
    "# associate the trajectories\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref_unassociated, traj_est_unassociated)\n",
    "\n",
    "print \"traj_ref: \", traj_ref\n",
    "print \"traj_est: \", traj_est\n",
    "\n",
    "# Associate timestamps between the two DataFrames to get a gt DataFrame with only associated timestamps.\n",
    "#gt_rel_df = time_associate_df(gt_df, mono_df)\n",
    "\n",
    "# Convert the absolute poses (world frame) of the gt DataFrame to relative poses.\n",
    "\n",
    "# Save this relative-pose ground truth file to disk as a csv for later use, if needed.\n",
    "# gt_rel_filename = \"/home/marcus/output_gt_rel_poses_mono.csv\"\n",
    "# gt_rel_df.to_csv(filename, sep=',', columns=['x', 'y', 'z', 'qw', 'qx', 'qy', 'qz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RPE for entire relative trajectory.\n",
    "rpe_rot = get_rpe((traj_ref, traj_est), metrics.PoseRelation.rotation_angle_deg)\n",
    "rpe_tran = get_rpe((traj_ref, traj_est), metrics.PoseRelation.translation_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot RPE of trajectory rotation and translation parts.\n",
    "\n",
    "# important: restrict data to delta ids for plot.\n",
    "traj_ref_plot = copy.deepcopy(traj_ref)\n",
    "traj_est_plot = copy.deepcopy(traj_est)\n",
    "traj_ref_plot.reduce_to_ids(rpe_rot.delta_ids)\n",
    "traj_est_plot.reduce_to_ids(rpe_rot.delta_ids)\n",
    "seconds_from_start = [t - traj_est.timestamps[0] for t in traj_est.timestamps[1:]]\n",
    "\n",
    "plot_rpe(seconds_from_start, rpe_rot)\n",
    "plot_rpe(seconds_from_start, rpe_tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend Stereo Ransac Poses (RPE)\n",
    "\n",
    "Calculate relative-pose-error (RPE) for the stereo ransac poses obtained in the frontend.\n",
    "\n",
    "This is done in the same way as in the mono module.\n",
    "\n",
    "This gives insight into the accuracy of the RANSAC 3-point method employed in the frontend.\n",
    "\n",
    "NOTE: gt_df is read from the ground-truth csv. It expects the timestamp to be the first column. Make sure to comment out `rename_euroc_gt_df(gt_df)` in the second cell below if you are not using a csv with the EuRoC header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth and estimated data as csv DataFrames.\n",
    "gt_df = pd.read_csv(gt_data_file, sep=',', index_col=0)\n",
    "\n",
    "ransac_stereo_filename = os.path.join(os.path.expandvars(vio_output_dir), \"output_frontend_ransac_stereo.csv\")\n",
    "stereo_df = pd.read_csv(ransac_stereo_filename, sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = gt_df[~gt_df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make gt_df prettier.\n",
    "rename_euroc_gt_df(gt_df)\n",
    "gt_rel_df = convert_abs_traj_to_rel_traj(gt_df, to_scale=False)\n",
    "\n",
    "# convert to evo trajecotry objects\n",
    "traj_ref_unassociated = pandas_bridge.df_to_trajectory(gt_rel_df)\n",
    "\n",
    "# Use the mono ransac file as estimated trajectory.\n",
    "traj_est_unassociated = pandas_bridge.df_to_trajectory(stereo_df)\n",
    "\n",
    "# associate the trajectories\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref_unassociated, traj_est_unassociated)\n",
    "\n",
    "\n",
    "# # Associate timestamps between the two DataFrames to get a gt DataFrame with only associated timestamps.\n",
    "# gt_rel_df = time_associate_df(gt_df, stereo_df)\n",
    "\n",
    "# # Convert the absolute poses (world frame) of the gt DataFrame to relative poses.\n",
    "# gt_rel_df = convert_abs_traj_to_rel_traj(gt_rel_df, to_scale=True)\n",
    "\n",
    "# Save this relative-pose ground truth file to disk as a csv for later use, if needed.\n",
    "# gt_rel_filename = \"/home/marcus/output_gt_rel_poses_mono.csv\"\n",
    "# gt_rel_df.to_csv(filename, sep=',', columns=['x', 'y', 'z', 'qw', 'qx', 'qy', 'qz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the gt relative-pose DataFrame to a trajectory object.\n",
    "traj_ref = pandas_bridge.df_to_trajectory(gt_rel_df)\n",
    "\n",
    "# Use the mono ransac file as estimated trajectory.\n",
    "# traj_est_unassociated = file_interface.read_swe_csv_trajectory(ransac_mono_filename)\n",
    "traj_est_unassociated = pandas_bridge.df_to_trajectory(stereo_df)\n",
    "\n",
    "# Associate the data.\n",
    "traj_est = copy.deepcopy(traj_est_unassociated)\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est)\n",
    "\n",
    "print \"traj_ref: \", traj_ref\n",
    "print \"traj_est: \", traj_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RPE for entire relative trajectory.\n",
    "rpe_rot = get_rpe((traj_ref, traj_est), metrics.PoseRelation.rotation_angle_deg)\n",
    "rpe_tran = get_rpe((traj_ref, traj_est), metrics.PoseRelation.translation_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RPE of trajectory rotation and translation parts.\n",
    "\n",
    "# important: restrict data to delta ids for plot.\n",
    "traj_ref_plot = copy.deepcopy(traj_ref)\n",
    "traj_est_plot = copy.deepcopy(traj_est)\n",
    "traj_ref_plot.reduce_to_ids(rpe_rot.delta_ids)\n",
    "traj_est_plot.reduce_to_ids(rpe_rot.delta_ids)\n",
    "seconds_from_start = [t - traj_est.timestamps[0] for t in traj_est.timestamps[1:]]\n",
    "\n",
    "plot_rpe(seconds_from_start, rpe_rot)\n",
    "plot_rpe(seconds_from_start, rpe_tran)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
