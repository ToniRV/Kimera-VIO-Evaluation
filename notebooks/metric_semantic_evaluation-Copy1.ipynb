{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glog as log\n",
    "import copy\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d import JVisualizer\n",
    "import pandas as pd\n",
    "\n",
    "from evaluation.tools.mesh import Mesh\n",
    "from evaluation.tools.mesh_evaluator import MeshEvaluator\n",
    "\n",
    "# Rotation matrices:\n",
    "# East North Up (ENU) frame to Unity's world frame of reference\n",
    "enu_R_unity = np.array([[1, 0, 0],\n",
    "                        [0, 0, 1],\n",
    "                        [0, 1, 0]])\n",
    "unity_R_enu = np.transpose(enu_R_unity)\n",
    "\n",
    "# Right Handed frame to Unity's Left Handed frame of reference\n",
    "righthand_R_lefthand = np.array([[1, 0, 0],\n",
    "                                 [0, -1, 0],\n",
    "                                 [0, 0, 1]])\n",
    "lefthand_R_righthand = np.transpose(righthand_R_lefthand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL PATHS BELOW\n",
    "#gt_mesh_path = \"/home/tonirv/Downloads/tesse_multiscene_office1_3d_semantic_v5.ply\"\n",
    "#est_mesh_path = \"/home/tonirv/Downloads/tesse_semantics_2.ply\"\n",
    "\n",
    "#gt_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/semantic_mesh_tonirv_ld_9118_6487309760727328010.ply\"\n",
    "#est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/semantic_mesh_tonirv_ld_9118_6487309760727328010.ply\"\n",
    "\n",
    "#gt_mesh_path = \"/home/tonirv/Downloads/tesse_multiscene_office1_3d_semantic_v5.ply\"\n",
    "#est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/tesse_semantics_3.ply\"\n",
    "\n",
    "gt_mesh_path = \"/home/tonirv/Downloads/office1_toni.ply\"\n",
    "est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/office2_v3.ply\"\n",
    "#est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/office2_v3_sparkvio.ply\"\n",
    "#est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/office2_v3_sparkvio_dense_stereo.ply\"\n",
    "\n",
    "gt_mesh_path = \"/home/tonirv/datasets/euroc/EuRoC/V1_01_easy/mav0/pointcloud0/data.ply\"\n",
    "est_mesh_path = \"/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/mesh_results/euroc_v1_02_spark_vio.ply\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ground-truth mesh...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Mesh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a93b41f10a22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Ground-truth mesh...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgt_mesh_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_mesh_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Estimated mesh...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mest_mesh_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_mesh_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Mesh' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Loading Ground-truth mesh...\")\n",
    "gt_mesh_original = Mesh(gt_mesh_path)\n",
    "print(\"Loading Estimated mesh...\")\n",
    "est_mesh_original = Mesh(est_mesh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Meshes to same frame of reference\n",
    "gt_mesh = copy.deepcopy(gt_mesh_original)\n",
    "est_mesh = copy.deepcopy(est_mesh_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming mesh according to left matrix:\n",
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Align Pointclouds Manually:\n",
    "#est_mesh.mesh_o3d.translate([0, -5, 0])\n",
    "#gt_mesh.transform_left(righthand_R_lefthand)\n",
    "gt_mesh.transform_left(enu_R_unity)\n",
    "#o3d.io.write_triangle_mesh(\"office1_toni_enu.ply\", gt_mesh.mesh_o3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.get_render_option().mesh_show_back_face = True\n",
    "vis.add_geometry(est_mesh.mesh_o3d)\n",
    "vis.add_geometry(gt_mesh.mesh_o3d)\n",
    "vis.add_geometry(o3d.geometry.create_mesh_coordinate_frame(size=4))\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_SAMPLES=1000000\n",
    "gt_pcl = o3d.geometry.sample_points_uniformly(gt_mesh.mesh_o3d, NUMBER_OF_SAMPLES)\n",
    "# Don't sample estimated mesh, just pick vertices, otw you'll be mixing colors...\n",
    "# est_pcl = o3d.geometry.sample_points_uniformly(est_mesh.mesh_o3d, NUMBER_OF_SAMPLES)\n",
    "est_pcl = o3d.io.read_point_cloud(est_mesh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normals for nice visualization\n",
    "# THIS COLORS THE PCL?>>>>>????\n",
    "#o3d.geometry.estimate_normals(\n",
    "#        est_pcl,\n",
    "#        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1,\n",
    "#                                                          max_nn=5))\n",
    "#o3d.geometry.estimate_normals(\n",
    "#        gt_pcl,\n",
    "#        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1,\n",
    "#                                                          max_nn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.get_render_option().mesh_show_back_face = True\n",
    "vis.add_geometry(gt_pcl)\n",
    "vis.add_geometry(est_pcl)\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICP\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "def draw_correspondences(source, target, correspondences):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    #source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    #target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    o3d.visualization.draw_geometries([source_temp, #target_temp, \n",
    "                                       correspondences])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICP params\n",
    "ICP_THRESHOLD = 1.5\n",
    "import math\n",
    "yaw = 0\n",
    "tx = 0\n",
    "ty = 0\n",
    "tz = 0\n",
    "if False:\n",
    "    yaw = 44\n",
    "    tx = 18.5\n",
    "    ty = 25\n",
    "    tz = 2.5\n",
    "yaw_rad = math.radians(yaw)\n",
    "trans_init = np.asarray([[math.cos(yaw_rad), -math.sin(yaw_rad), 0.0, tx],\n",
    "                         [math.sin(yaw_rad), math.cos(yaw_rad), 0.0, ty],\n",
    "                         [0.0, 0.0, 1.0, tz],\n",
    "                         [0.0, 0.0, 0.0, 1.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize initial registration problem\n",
    "draw_registration_result(est_pcl, gt_pcl, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate current fit between pointclouds\n",
    "evaluation = o3d.registration.evaluate_registration(est_pcl, gt_pcl, ICP_THRESHOLD, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial registration\n",
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.099000, and correspondence_set size of 475061\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial registration\")\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.registration.registration_icp(\n",
    "    est_pcl, gt_pcl, ICP_THRESHOLD, trans_init,\n",
    "    o3d.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.registration.ICPConvergenceCriteria(max_iteration = 2000))\n",
    "correspondences = reg_p2p.correspondence_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registration::RegistrationResult with fitness = 1.000000, inlier_rmse = 0.079332, and correspondence_set size of 475061\n",
      "Access transformation to get result.\n",
      "\n",
      "Transformation is:\n",
      "[[ 0.99999515  0.00157796 -0.00268335  0.08755623]\n",
      " [-0.00157206  0.99999634  0.00220284  0.07571541]\n",
      " [ 0.00268681 -0.00219861  0.99999397  0.04083394]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "Correspondence Set:\n",
      "std::vector<Eigen::Vector2i> with 475061 elements.\n",
      "Use numpy.asarray() to access data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reg_p2p)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Correspondence Set:\")\n",
    "print(reg_p2p.correspondence_set)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tf to 3D mesh and write:\n",
    "est_mesh_icped = copy.deepcopy(est_mesh.mesh_o3d).transform(reg_p2p.transformation)\n",
    "o3d.visualization.draw_geometries([est_mesh_icped])\n",
    "o3d.io.write_triangle_mesh(\"office2_v3_icped.ply\", est_mesh_icped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Registration Result\n",
    "draw_registration_result(est_pcl, gt_pcl, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Only Correspondences\n",
    "c2c_lines = o3d.geometry.create_line_set_from_point_cloud_correspondences(est_pcl, gt_pcl, correspondences)\n",
    "o3d.visualization.draw_geometries([c2c_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw PointClouds and Correspondences\n",
    "draw_correspondences(est_pcl, gt_pcl, c2c_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corresp(est_pcl, gt_pcl, correspondences):\n",
    "    total_negative_matches = 0\n",
    "    total_positive_matches = 0\n",
    "    total_correspondences = len(correspondences)\n",
    "    for correspondence in correspondences:\n",
    "        if np.allclose(est_pcl.colors[correspondence[0]],\n",
    "                       gt_pcl.colors[correspondence[1]]):\n",
    "            total_positive_matches += 1\n",
    "        else:\n",
    "            total_negative_matches += 1\n",
    "\n",
    "    print(\"Positive color matches: \",total_positive_matches)\n",
    "    print(\"Negative color matches: \", total_negative_matches)\n",
    "    print(\"Total correspondences: \", total_correspondences)\n",
    "    assert(total_correspondences == total_negative_matches + total_positive_matches)\n",
    "    print (\"Positive: {}  % \".format(total_positive_matches / total_correspondences * 100))\n",
    "    print (\"Negative: {}  % \".format(total_negative_matches / total_correspondences * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Positive color matches: ', 425453)\n",
      "('Negative color matches: ', 49608)\n",
      "('Total correspondences: ', 475061)\n",
      "Positive: 89.5575515565  % \n",
      "Negative: 10.4424484435  % \n"
     ]
    }
   ],
   "source": [
    "calc_corresp(est_pcl, gt_pcl, correspondences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Semantic Labels\n",
    "df = pd.read_csv('/home/tonirv/Code/ROS/flight_goggles_ws/src/voxblox/voxblox_ros/cfg/tesse_multiscene_office1_segmentation_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = copy.deepcopy(df)\n",
    "normalized_df['normalized_red'] = df['red'] / 255\n",
    "normalized_df['normalized_green'] = df['green'] / 255\n",
    "normalized_df['normalized_blue'] = df['blue'] / 255\n",
    "#print(sum(np.isclose(normalized_df['normalized_red'], gt_pcl.colors[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "\n",
    "from numpy import all, array, uint8\n",
    "\n",
    "\n",
    "class hashable(object):\n",
    "    r'''Hashable wrapper for ndarray objects.\n",
    "        Instances of ndarray are not hashable, meaning they cannot be added to\n",
    "        sets, nor used as keys in dictionaries. This is by design - ndarray\n",
    "        objects are mutable, and therefore cannot reliably implement the\n",
    "        __hash__() method.\n",
    "        The hashable class allows a way around this limitation. It implements\n",
    "        the required methods for hashable objects in terms of an encapsulated\n",
    "        ndarray object. This can be either a copied instance (which is safer)\n",
    "        or the original object (which requires the user to be careful enough\n",
    "        not to modify it).\n",
    "    '''\n",
    "    def __init__(self, wrapped, tight=False):\n",
    "        r'''Creates a new hashable object encapsulating an ndarray.\n",
    "            wrapped\n",
    "                The wrapped ndarray.\n",
    "            tight\n",
    "                Optional. If True, a copy of the input ndaray is created.\n",
    "                Defaults to False.\n",
    "        '''\n",
    "        self.__tight = tight\n",
    "        self.__wrapped = array(wrapped) if tight else wrapped\n",
    "        self.__hash = int(sha1(wrapped.view(uint8)).hexdigest(), 16)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return all(self.__wrapped == other.__wrapped)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.__hash\n",
    "\n",
    "    def unwrap(self):\n",
    "        r'''Returns the encapsulated ndarray.\n",
    "            If the wrapper is \"tight\", a copy of the encapsulated ndarray is\n",
    "            returned. Otherwise, the encapsulated ndarray itself is returned.\n",
    "        '''\n",
    "        if self.__tight:\n",
    "            return array(self.__wrapped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to hash, we have ids now\n",
    "red_col = df['red'].to_numpy()\n",
    "blue_col = df['blue'].to_numpy()\n",
    "green_col = df['green'].to_numpy()\n",
    "\n",
    "hash_factor = 10\n",
    "def f(x):    \n",
    "    return str(int(x['normalized_red']*hash_factor))+str(int(x['normalized_green']*hash_factor))+str(int(x['normalized_blue']*hash_factor))\n",
    "\n",
    "hashed_df = copy.deepcopy(normalized_df)\n",
    "hashed_df['hash'] = hashed_df.apply(f, axis=1)\n",
    "hashed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table from color to id.\n",
    "def label_from_hash(hash):\n",
    "    return hashed_df.loc[(hashed_df['hash'] == hash)].iat[0, 5]\n",
    "def hash_from_color(color):\n",
    "    r = int(color[0]*hash_factor)\n",
    "    g = int(color[1]*hash_factor)\n",
    "    b = int(color[2]*hash_factor)\n",
    "    return str(r)+str(g)+str(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_from_color([0.007843,0.403922,0.278431])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_to_label_dict = {i: label_from_hash(i) for i in hashed_df['hash'].unique().tolist()}\n",
    "print hash_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare labels between correspondences:\n",
    "unique_ids = hashed_df['id'].unique().tolist()\n",
    "unique_ids.sort()\n",
    "print unique_ids\n",
    "confusion_matrix = {i:{j:0 for j in unique_ids} for i in unique_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_per_label_corresp():\n",
    "    for correspondence in correspondences:\n",
    "        est_pcl_color = est_pcl.colors[correspondence[0]]\n",
    "        gt_pcl_color  = gt_pcl.colors[correspondence[1]]\n",
    "        try:\n",
    "            est_label_id = hash_to_label_dict[hash_from_color(est_pcl_color)]\n",
    "            gt_label_id = hash_to_label_dict[hash_from_color(gt_pcl_color)]\n",
    "        except:\n",
    "            print hash_from_color(gt_pcl_color)\n",
    "            #print \"Est: \", est_pcl_color\n",
    "            #print \"GT: \", gt_pcl_color\n",
    "            \n",
    "        confusion_matrix[est_label_id][gt_label_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_per_label_corresp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print hashed_df.loc[(hashed_df['id'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for heatmap:\n",
    "def label_id_to_name(id):\n",
    "    if id == 0:\n",
    "        return r'$\\text{Unknown}$'\n",
    "    elif id == 1:\n",
    "        return r'$\\text{Airvent.}$'\n",
    "    elif id == 2:\n",
    "        return r'$\\text{Book}$'\n",
    "    elif id == 3:\n",
    "        return r'$\\text{Floor}$'\n",
    "    elif id == 4:\n",
    "        return r'$\\text{Ceil.}$'\n",
    "    elif id == 5:\n",
    "        return r'$\\text{Chair}$'\n",
    "    elif id == 6:\n",
    "        return \"\"\n",
    "    elif id == 7:\n",
    "        return r'$\\text{Couch}$'\n",
    "    elif id == 8:\n",
    "        return \"\"\n",
    "    elif id == 9:\n",
    "        return r'$\\text{Shelf}$'\n",
    "    elif id == 10:\n",
    "        return r'$\\text{Fan}$'\n",
    "    elif id == 11:\n",
    "        return r'$\\text{Lamp}$'\n",
    "    elif id == 12:\n",
    "        return r'$\\text{Paint.}$'\n",
    "    elif id == 13:\n",
    "        return r'$\\text{Plant}$'\n",
    "    elif id == 14:\n",
    "        return r'$\\text{Sign}$'\n",
    "    elif id == 15:\n",
    "        return r'$\\text{Stairs}$'\n",
    "    elif id == 16:\n",
    "        return r'$\\text{Table}$'\n",
    "    elif id == 17:\n",
    "        return r'$\\text{Screen}$'\n",
    "    elif id == 18:\n",
    "        return r'$\\text{Bin}$'\n",
    "    elif id == 19:\n",
    "        return r'$\\text{Wall}$'\n",
    "    \n",
    "remove_keys = [0, 2, 4, 13, 14, 15]        \n",
    "x = [label_id_to_name(id) for id in unique_ids if id not in remove_keys ]\n",
    "y = x\n",
    "z = []\n",
    "for est_key, gt in confusion_matrix.items():\n",
    "    if est_key not in remove_keys:\n",
    "        values = []\n",
    "        for gt_key, value in gt.items():\n",
    "            if gt_key not in remove_keys:\n",
    "                values.append(value)\n",
    "        z.append(values)\n",
    "print x\n",
    "print y\n",
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import Data\n",
    "trace1 = {\n",
    "  \"type\": \"heatmap\", \n",
    "  \"x\": x, \n",
    "  \"y\": y, \n",
    "  \"zmax\": 10000, \n",
    "  \"zmin\": 0, \n",
    "  \"z\": z, \n",
    "  \"colorscale\": [[0, \"rgb(255,245,240)\"], [0.2, \"rgb(254,224,210)\"], [0.4, \"rgb(252,187,161)\"],  [0.5, \"rgb(252,146,114)\"], [0.6, \"rgb(251,106,74)\"],   [0.7, \"rgb(239,59,44)\"],  [0.8, \"rgb(203,24,29)\"], [0.9, \"rgb(165,15,21)\"], [1, \"rgb(103,0,13)\"]],\n",
    "  \"autocolorscale\": False\n",
    "}\n",
    "data = Data([trace1])\n",
    "\n",
    "layout = {\n",
    "  \"title\": r'$\\text{Confusion Matrix}$', \n",
    "  \"width\": 400,\n",
    "  \"height\": 400,\n",
    "  \"xaxis\": {\n",
    "    \"title\": r'$\\text{Predicted}$',\n",
    "    \"titlefont\": {\n",
    "      \"size\": 18\n",
    "    }\n",
    "  }, \n",
    "  \"yaxis\": {\n",
    "    \"title\": r'$\\text{Ground-Truth}$', \n",
    "    \"titlefont\": {\n",
    "      \"size\": 18\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IoU:\n",
    "# TODO(Toni): Ignore Unknown!\n",
    "np_confusion_matrix = np.matrix(z)\n",
    "TP = np.diag(np_confusion_matrix)\n",
    "FP_TP = np.sum(np_confusion_matrix, axis=0, dtype = 'int')\n",
    "FP = np.squeeze(np.asarray(FP_TP)) - TP\n",
    "FN_TP = np.sum(np_confusion_matrix, axis=1)\n",
    "FN = np.squeeze(np.asarray(FN_TP)) - TP\n",
    "TN = np.sum(np_confusion_matrix) - TP - FP - FN\n",
    "print \"TP:\\n\", TP\n",
    "print \"FP:\\n\", FP\n",
    "print \"FN:\\n\", FN\n",
    "print \"TN:\\n\", TN\n",
    "#iou = cm.diag() / (cm.sum(dim=1) + cm.sum(dim=0) - cm.diag() + 1e-15)\n",
    "IoU = TP / (np.squeeze(np.asarray(FP_TP)) + np.squeeze(np.asarray(FN_TP)) - TP + 1e-15)\n",
    "print \"IoU:\\n\", IoU\n",
    "mIoU = np.mean(IoU)\n",
    "print \"mIoU:\\n\", mIoU\n",
    "mAcc = np.sum(TP) / np.sum(np_confusion_matrix)\n",
    "print \"mAcc:\\n\", mAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Orca for figure generation:\n",
    "import plotly.io as pio\n",
    "import plotly\n",
    "# Install orca using the AppImage (if you are in Ubuntu)\n",
    "plotly.io.orca.config.executable = '/usr/local/bin/orca'\n",
    "# Print orca config to check: pio.orca.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figures to images:\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")\n",
    "#fig.write_image(\"/home/tonirv/Documents/Research/Papers/2019w-IROS-SparkVIO/img/confusion_matrix.svg\")\n",
    "#fig.write_image(\"/home/tonirv/Documents/Research/Papers/2019w-IROS-SparkVIO/img/confusion_matrix.png\")\n",
    "#fig.write_image(\"/home/tonirv/Documents/Research/Papers/2019w-IROS-SparkVIO/img/confusion_matrix.eps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
